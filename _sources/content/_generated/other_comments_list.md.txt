|Comments|
|--------|
|I think the project is excellent and the organization and planning that they have been carrying out is very good. (Original in Spanish: Creo que el proyecto es excelente y la organización y planificación que han venido llevando a cabo es muy buena.)|
|Static typing. Being able to check dtypes and dimensions statically with Mypy would be nice, but even rudimentary static typing support improves documentation (especially with Sphinx’s autodoc feature). The ideal would be a static typing language powerful enough to describe conformable arrays: e.g., my_func(a: m by n, b: n by k) but somehow saying that both arrays have a dtype that can be safely cast to float32.|
|The only really high-priority issue for me is othogonal indexing, all other priorities pale in comparison.|
|Not really missing stuff for what I do, that‘s why I selected, that I‘m currently not interested in contributing. Numpy is generally quite fine.|
|To me, a GPU backend is the single and most important objective that Numpy should aim for.|
|uarray and unumpy|
|I'd like to have a way to tell mypy which ndim/shape/dtype is expected, and I'd like for mypy to be able to find some errors with such information. In a dream world, that would work with `numpy.einsum`.|
|Because there seems to be no plan for a NumPy Version 2, I think that a roadmap and timeline to consolidate and clean up the NumPy API would be very helpful.  This ties in to the informal style guide proposed above.|
|There's a few things that have been staged for "2.0" for many MANY years... the fact it's been this long I believe indicates a lot of problems - I think numpy as a whole needs to identify and resolve the issues that are hamstringing them so horribly.|
|Micropython support for numpy, perhaps on a module to module basis would be VERY useful|
|Type hinting for ndarrays supporting size in order to allow autocompletion.|
|Is there a numpy tutorial?|
|Having to write out `np.asarray(my_list)` or `np.array([[...]])` is workable, but it would be nice to have something more compact so that math could stand out more. Perhaps making performant helper, like `A_(my_list)`, or `A_[[...]]`, might help? Then I could change `np.array([[1, 2], [3, 4]]) @ np.array([10, 20])` as `A_[[1, 2], [3, 4]] @ A_[10, 20]`.  Scalars - the contract for scalars (np.array(()), np.generic, np.ndarray.item, etc.) has always thrown me off a bit. np.isscalar is also a bit confusing, i.e. people have to use `np.dim(x) == 0`, which feels awkward.  User dtypes: https://numpy.org/devdocs/user/c-info.beyond-basics.html#user-defined-data-types It would be nice if there were a concise overview of different ways of doing custom dytpes (e.g. dtype=object, structured dtypes, user dtypes). I've always felt like writing this out whenever I comment in issues, so it'd be nice to have good docs for this, and references back to this section. As far as the feature goes, it would also be nice if ctors / dtors worked for non-POD data (issue 10721).  Records / recarrays - these always confuse me in how I need to construct them and use them. TBH, MATLAB's struct arrays were also confusing, but did feel more cohesive (and simple) to me. Overall, it would be nice if there were a way to remove the need for one of the types, and then try to make attribute access less leaky (e.g. if I define a field like "size" which conflicts with the builtin property). Also, there aren't docs for examples of records linked from `np.record`s page: https://numpy.org/devdocs/reference/generated/numpy.record.html#numpy.record|
|Work with other projects like Numba, Cython and Pypy to create a JIT.|
|The new numpy nditer C API is not yet well supported by Cython. In fact, it would be super nice, to have a high-level Cython interface to this, such that I could use nditer within Cython (perhaps even within nogil), but without needing to care about the bloody C details. Not sure if that is possible at all, but it would be cool.|
|Numpy is used in many code bases, so breaking backwards-compatibility is hard. There are however some inconsistencies in numpy which could be fixed to make it a better library. I wish numpy was more lenient on breaking changes at the cost of increasing the major version.|
|Helping CPython refactor their C-API should open up opportunities for accelerating all other Python code. But this is only feasible if big projects like Numpy and scipy are compatible. This seems like an area where the new funding work group could help arrange funding for both Numpy and CPython|
|Defining and improving high-performance interop with other libraries - e.g. PyTorch/Tensorflow/cuPY|
|Reactivity and first impression for new contributor would be good. The team is super friendly but unless you are already well versed, it can be easy to get lost amount all open PRs.|
|The one general area I currently experience the most issues with in NumPy is custom array-like types and the possible extension to custom dtypes. NEP 18 opened the way for a lot of great inter-library array-like type compatibility (especially for my favored use case of unit-aware calculations), but there is still progress to be made. Two examples are NumPy masked arrays not working properly with other array-like types that wrap them and continued progress being made for units-on-dtype arrays (rather than subclasses or wrapped arrays).|
|Related to the above, I think one of the biggest concerns related to the scientific Python ecosystem (and, given it's position in that ecosystem, NumPy itself) is fragmentation of scientific Python computing tools as a result of the introduction of many new array libraries. It's not clear what more the NumPy community could be doing in this regard, and the work that is already being dedicated towards interoperability is very valuable. I would just like to reiterate the importance of this work and think the fragmentation of the ecosystem into multiple ecosystems based on different underlying array libraries would be detrimental to scientific Python as a whole.|
